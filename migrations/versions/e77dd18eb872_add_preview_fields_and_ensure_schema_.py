"""Add preview fields and ensure schema consistency

Revision ID: e77dd18eb872
Revises: 000000000001
Create Date: 2025-06-03 15:06:58.042947

"""
from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision = 'e77dd18eb872'
down_revision = '000000000001'
branch_labels = None
depends_on = None


def upgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    with op.batch_alter_table('batch_jobs', schema=None) as batch_op:
        batch_op.alter_column('start_time',
               existing_type=postgresql.TIMESTAMP(),
               type_=sa.DateTime(timezone=True),
               existing_nullable=False)
        batch_op.alter_column('end_time',
               existing_type=postgresql.TIMESTAMP(),
               type_=sa.DateTime(timezone=True),
               existing_nullable=True)

    with op.batch_alter_table('classifications', schema=None) as batch_op:
        batch_op.alter_column('classification_date',
               existing_type=postgresql.TIMESTAMP(),
               type_=sa.DateTime(timezone=True),
               existing_nullable=True)
        batch_op.drop_index('ix_classifications_category')
        batch_op.drop_index('ix_classifications_document_id')

    with op.batch_alter_table('clients', schema=None) as batch_op:
        batch_op.alter_column('created_date',
               existing_type=postgresql.TIMESTAMP(),
               type_=sa.DateTime(timezone=True),
               existing_nullable=True)

    with op.batch_alter_table('communication_focus', schema=None) as batch_op:
        batch_op.alter_column('created_date',
               existing_type=postgresql.TIMESTAMP(),
               type_=sa.DateTime(timezone=True),
               existing_nullable=True)
        batch_op.drop_index('ix_communication_focus_document_id')
        batch_op.drop_index('ix_communication_focus_primary_issue')

    with op.batch_alter_table('design_elements', schema=None) as batch_op:
        batch_op.alter_column('created_date',
               existing_type=postgresql.TIMESTAMP(),
               type_=sa.DateTime(timezone=True),
               existing_nullable=True)
        batch_op.drop_index('ix_design_elements_document_id')
        batch_op.drop_index('ix_design_elements_geographic_location')

    with op.batch_alter_table('document_scorecards', schema=None) as batch_op:
        batch_op.alter_column('review_date',
               existing_type=postgresql.TIMESTAMP(),
               type_=sa.DateTime(timezone=True),
               existing_nullable=True)
        batch_op.alter_column('created_date',
               existing_type=postgresql.TIMESTAMP(),
               type_=sa.DateTime(timezone=True),
               existing_nullable=True)
        batch_op.alter_column('updated_date',
               existing_type=postgresql.TIMESTAMP(),
               type_=sa.DateTime(timezone=True),
               existing_nullable=True)

    with op.batch_alter_table('documents', schema=None) as batch_op:
        batch_op.add_column(sa.Column('preview_status', sa.Text(), nullable=True))
        batch_op.add_column(sa.Column('s3_preview_key', sa.Text(), nullable=True))
        batch_op.add_column(sa.Column('preview_task_id', sa.Text(), nullable=True))
        batch_op.add_column(sa.Column('preview_error_message', sa.Text(), nullable=True))
        batch_op.add_column(sa.Column('preview_generated_at', sa.DateTime(timezone=True), nullable=True))
        batch_op.alter_column('upload_date',
               existing_type=postgresql.TIMESTAMP(),
               type_=sa.DateTime(timezone=True),
               existing_nullable=False)
        batch_op.drop_index('documents_embeddings_idx', postgresql_with={'lists': '100'}, postgresql_using='ivfflat')
        batch_op.drop_index('ix_documents_filename')
        batch_op.drop_index('ix_documents_search_vector_gin', postgresql_using='gin')
        batch_op.drop_index('ix_documents_status')
        batch_op.drop_index('ix_documents_upload_date')

    with op.batch_alter_table('dropbox_syncs', schema=None) as batch_op:
        batch_op.alter_column('sync_date',
               existing_type=postgresql.TIMESTAMP(),
               type_=sa.DateTime(timezone=True),
               existing_nullable=True)

    with op.batch_alter_table('entities', schema=None) as batch_op:
        batch_op.alter_column('created_date',
               existing_type=postgresql.TIMESTAMP(),
               type_=sa.DateTime(timezone=True),
               existing_nullable=True)
        batch_op.drop_index('ix_entities_client_name')
        batch_op.drop_index('ix_entities_document_id')
        batch_op.drop_index('ix_entities_opponent_name')

    with op.batch_alter_table('extracted_text', schema=None) as batch_op:
        batch_op.alter_column('extraction_date',
               existing_type=postgresql.TIMESTAMP(),
               type_=sa.DateTime(timezone=True),
               existing_nullable=True)
        batch_op.drop_index('ix_extracted_text_document_id')
        batch_op.drop_index('ix_extracted_text_main_message')
        batch_op.drop_index('ix_extracted_text_search_vector_gin', postgresql_using='gin')
        batch_op.drop_index('ix_extracted_text_supporting_text')
        batch_op.drop_column('search_vector')

    with op.batch_alter_table('keyword_synonyms', schema=None) as batch_op:
        batch_op.drop_index('ix_keyword_synonyms_synonym')
        batch_op.drop_index('ix_keyword_synonyms_taxonomy_id')

    with op.batch_alter_table('keyword_taxonomy', schema=None) as batch_op:
        batch_op.alter_column('created_date',
               existing_type=postgresql.TIMESTAMP(),
               type_=sa.DateTime(timezone=True),
               existing_nullable=True)
        batch_op.drop_index('ix_keyword_taxonomy_primary_category')
        batch_op.drop_index('ix_keyword_taxonomy_subcategory')
        batch_op.drop_index('ix_keyword_taxonomy_term')

    with op.batch_alter_table('llm_analysis', schema=None) as batch_op:
        batch_op.alter_column('analysis_date',
               existing_type=postgresql.TIMESTAMP(),
               type_=sa.DateTime(timezone=True),
               existing_nullable=True)
        batch_op.drop_index('ix_llm_analysis_campaign_type')
        batch_op.drop_index('ix_llm_analysis_document_id')
        batch_op.drop_index('ix_llm_analysis_document_tone')
        batch_op.drop_index('ix_llm_analysis_election_year')
        batch_op.drop_index('ix_llm_analysis_search_vector_gin', postgresql_using='gin')
        batch_op.drop_index('ix_llm_analysis_summary_description')
        batch_op.drop_index('llm_analysis_embeddings_idx', postgresql_with={'lists': '100'}, postgresql_using='ivfflat')
        batch_op.drop_column('search_vector')

    with op.batch_alter_table('llm_keywords', schema=None) as batch_op:
        batch_op.drop_index('ix_llm_keywords_keyword')
        batch_op.drop_index('ix_llm_keywords_llm_analysis_id')

    with op.batch_alter_table('search_feedback', schema=None) as batch_op:
        batch_op.alter_column('feedback_date',
               existing_type=postgresql.TIMESTAMP(),
               type_=sa.DateTime(timezone=True),
               existing_nullable=True)

    # ### end Alembic commands ###


def downgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    with op.batch_alter_table('search_feedback', schema=None) as batch_op:
        batch_op.alter_column('feedback_date',
               existing_type=sa.DateTime(timezone=True),
               type_=postgresql.TIMESTAMP(),
               existing_nullable=True)

    with op.batch_alter_table('llm_keywords', schema=None) as batch_op:
        batch_op.create_index('ix_llm_keywords_llm_analysis_id', ['llm_analysis_id'], unique=False)
        batch_op.create_index('ix_llm_keywords_keyword', ['keyword'], unique=False)

    with op.batch_alter_table('llm_analysis', schema=None) as batch_op:
        batch_op.add_column(sa.Column('search_vector', postgresql.TSVECTOR(), autoincrement=False, nullable=True))
        batch_op.create_index('llm_analysis_embeddings_idx', ['embeddings'], unique=False, postgresql_with={'lists': '100'}, postgresql_using='ivfflat')
        batch_op.create_index('ix_llm_analysis_summary_description', ['summary_description'], unique=False)
        batch_op.create_index('ix_llm_analysis_search_vector_gin', ['search_vector'], unique=False, postgresql_using='gin')
        batch_op.create_index('ix_llm_analysis_election_year', ['election_year'], unique=False)
        batch_op.create_index('ix_llm_analysis_document_tone', ['document_tone'], unique=False)
        batch_op.create_index('ix_llm_analysis_document_id', ['document_id'], unique=False)
        batch_op.create_index('ix_llm_analysis_campaign_type', ['campaign_type'], unique=False)
        batch_op.alter_column('analysis_date',
               existing_type=sa.DateTime(timezone=True),
               type_=postgresql.TIMESTAMP(),
               existing_nullable=True)

    with op.batch_alter_table('keyword_taxonomy', schema=None) as batch_op:
        batch_op.create_index('ix_keyword_taxonomy_term', ['term'], unique=False)
        batch_op.create_index('ix_keyword_taxonomy_subcategory', ['subcategory'], unique=False)
        batch_op.create_index('ix_keyword_taxonomy_primary_category', ['primary_category'], unique=False)
        batch_op.alter_column('created_date',
               existing_type=sa.DateTime(timezone=True),
               type_=postgresql.TIMESTAMP(),
               existing_nullable=True)

    with op.batch_alter_table('keyword_synonyms', schema=None) as batch_op:
        batch_op.create_index('ix_keyword_synonyms_taxonomy_id', ['taxonomy_id'], unique=False)
        batch_op.create_index('ix_keyword_synonyms_synonym', ['synonym'], unique=False)

    with op.batch_alter_table('extracted_text', schema=None) as batch_op:
        batch_op.add_column(sa.Column('search_vector', postgresql.TSVECTOR(), autoincrement=False, nullable=True))
        batch_op.create_index('ix_extracted_text_supporting_text', ['supporting_text'], unique=False)
        batch_op.create_index('ix_extracted_text_search_vector_gin', ['search_vector'], unique=False, postgresql_using='gin')
        batch_op.create_index('ix_extracted_text_main_message', ['main_message'], unique=False)
        batch_op.create_index('ix_extracted_text_document_id', ['document_id'], unique=False)
        batch_op.alter_column('extraction_date',
               existing_type=sa.DateTime(timezone=True),
               type_=postgresql.TIMESTAMP(),
               existing_nullable=True)

    with op.batch_alter_table('entities', schema=None) as batch_op:
        batch_op.create_index('ix_entities_opponent_name', ['opponent_name'], unique=False)
        batch_op.create_index('ix_entities_document_id', ['document_id'], unique=False)
        batch_op.create_index('ix_entities_client_name', ['client_name'], unique=False)
        batch_op.alter_column('created_date',
               existing_type=sa.DateTime(timezone=True),
               type_=postgresql.TIMESTAMP(),
               existing_nullable=True)

    with op.batch_alter_table('dropbox_syncs', schema=None) as batch_op:
        batch_op.alter_column('sync_date',
               existing_type=sa.DateTime(timezone=True),
               type_=postgresql.TIMESTAMP(),
               existing_nullable=True)

    with op.batch_alter_table('documents', schema=None) as batch_op:
        batch_op.create_index('ix_documents_upload_date', ['upload_date'], unique=False)
        batch_op.create_index('ix_documents_status', ['status'], unique=False)
        batch_op.create_index('ix_documents_search_vector_gin', ['search_vector'], unique=False, postgresql_using='gin')
        batch_op.create_index('ix_documents_filename', ['filename'], unique=False)
        batch_op.create_index('documents_embeddings_idx', ['embeddings'], unique=False, postgresql_with={'lists': '100'}, postgresql_using='ivfflat')
        batch_op.alter_column('upload_date',
               existing_type=sa.DateTime(timezone=True),
               type_=postgresql.TIMESTAMP(),
               existing_nullable=False)
        batch_op.drop_column('preview_generated_at')
        batch_op.drop_column('preview_error_message')
        batch_op.drop_column('preview_task_id')
        batch_op.drop_column('s3_preview_key')
        batch_op.drop_column('preview_status')

    with op.batch_alter_table('document_scorecards', schema=None) as batch_op:
        batch_op.alter_column('updated_date',
               existing_type=sa.DateTime(timezone=True),
               type_=postgresql.TIMESTAMP(),
               existing_nullable=True)
        batch_op.alter_column('created_date',
               existing_type=sa.DateTime(timezone=True),
               type_=postgresql.TIMESTAMP(),
               existing_nullable=True)
        batch_op.alter_column('review_date',
               existing_type=sa.DateTime(timezone=True),
               type_=postgresql.TIMESTAMP(),
               existing_nullable=True)

    with op.batch_alter_table('design_elements', schema=None) as batch_op:
        batch_op.create_index('ix_design_elements_geographic_location', ['geographic_location'], unique=False)
        batch_op.create_index('ix_design_elements_document_id', ['document_id'], unique=False)
        batch_op.alter_column('created_date',
               existing_type=sa.DateTime(timezone=True),
               type_=postgresql.TIMESTAMP(),
               existing_nullable=True)

    with op.batch_alter_table('communication_focus', schema=None) as batch_op:
        batch_op.create_index('ix_communication_focus_primary_issue', ['primary_issue'], unique=False)
        batch_op.create_index('ix_communication_focus_document_id', ['document_id'], unique=False)
        batch_op.alter_column('created_date',
               existing_type=sa.DateTime(timezone=True),
               type_=postgresql.TIMESTAMP(),
               existing_nullable=True)

    with op.batch_alter_table('clients', schema=None) as batch_op:
        batch_op.alter_column('created_date',
               existing_type=sa.DateTime(timezone=True),
               type_=postgresql.TIMESTAMP(),
               existing_nullable=True)

    with op.batch_alter_table('classifications', schema=None) as batch_op:
        batch_op.create_index('ix_classifications_document_id', ['document_id'], unique=False)
        batch_op.create_index('ix_classifications_category', ['category'], unique=False)
        batch_op.alter_column('classification_date',
               existing_type=sa.DateTime(timezone=True),
               type_=postgresql.TIMESTAMP(),
               existing_nullable=True)

    with op.batch_alter_table('batch_jobs', schema=None) as batch_op:
        batch_op.alter_column('end_time',
               existing_type=sa.DateTime(timezone=True),
               type_=postgresql.TIMESTAMP(),
               existing_nullable=True)
        batch_op.alter_column('start_time',
               existing_type=sa.DateTime(timezone=True),
               type_=postgresql.TIMESTAMP(),
               existing_nullable=False)

    # ### end Alembic commands ###
